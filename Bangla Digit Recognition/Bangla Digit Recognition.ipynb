{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bishwa/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "TRAINING_EPOCHS = 100\n",
    "BATCH_SIZE = 25\n",
    "DISPLAY_STEP = 10\n",
    "DROPOUT_CONV = 0.8\n",
    "DROPOUT_HIDDEN = 0.6\n",
    "VALIDATION_SIZE = 200      # Set to 0 to train on all available data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight initialization\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# Weight initialization (Xavier's init)\n",
    "def weight_xavier_init(n_inputs, n_outputs, uniform=True):\n",
    "    if uniform:\n",
    "        init_range = tf.sqrt(6.0 / (n_inputs + n_outputs))\n",
    "        return tf.random_uniform_initializer(-init_range, init_range)\n",
    "    else:\n",
    "        stddev = tf.sqrt(3.0 / (n_inputs + n_outputs))\n",
    "        return tf.truncated_normal_initializer(stddev=stddev)\n",
    "\n",
    "# Bias initialization\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# 2D convolution\n",
    "def conv2d(X, W):\n",
    "    return tf.nn.conv2d(X, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# Max Pooling\n",
    "def max_pool_2x2(X):\n",
    "    return tf.nn.max_pool(X, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# Serve data by batches\n",
    "def next_batch(batch_size):    \n",
    "    global train_images\n",
    "    global train_labels\n",
    "    global index_in_epoch\n",
    "    global epochs_completed\n",
    "    \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    # when all trainig data have been already used, it is reorder randomly    \n",
    "    if index_in_epoch > num_examples:\n",
    "        # finished epoch\n",
    "        epochs_completed += 1\n",
    "        # shuffle the data\n",
    "        perm = np.arange(num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        train_images = train_images[perm]\n",
    "        train_labels = train_labels[perm]\n",
    "        # start next epoch\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "        assert batch_size <= num_examples\n",
    "    end = index_in_epoch\n",
    "    return train_images[start:end], train_labels[start:end]\n",
    "\n",
    "# Convert class labels from scalars to one-hot vectors \n",
    "# 0 => [1 0 0 0 0 0 0 0 0 0]\n",
    "# 1 => [0 1 0 0 0 0 0 0 0 0]\n",
    "def dense_to_one_hot(labels_dense, num_classes):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(imgf, labelf, outf, n):\n",
    "    f = open(imgf, \"rb\")\n",
    "    o = open(outf, \"w\")\n",
    "    l = open(labelf, \"rb\")\n",
    "\n",
    "    f.read(16)\n",
    "    l.read(8)\n",
    "    images = []\n",
    "\n",
    "    for i in range(n):\n",
    "        image = [ord(l.read(1))]\n",
    "        for j in range(28*28):\n",
    "            image.append(ord(f.read(1)))\n",
    "        images.append(image)\n",
    "\n",
    "    for image in images:\n",
    "        o.write(\",\".join(str(pix) for pix in image)+\"\\n\")\n",
    "    f.close()\n",
    "    o.close()\n",
    "    l.close()\n",
    "\n",
    "convert(\"./all_data/train_images.txt\", \"./all_data/train_labels.txt\",\n",
    "        \"train.csv\", 2122)\n",
    "convert(\"./all_data/test_images.txt\", \"./all_data/test_labels.txt\",\n",
    "        \"test.csv\", 531)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Bangla data set (Train data from CSV file)\n",
    "data = pd.read_csv('all_data.csv')\n",
    "\n",
    "# Extracting images and labels from given data\n",
    "# For images\n",
    "images = data.iloc[:,1:].values\n",
    "images = images.astype(np.float)\n",
    "\n",
    "# Normalize from [0:255] => [0.0:1.0]\n",
    "images = np.multiply(images, 1.0 / 255.0)\n",
    "image_size = images.shape[1]\n",
    "image_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8)\n",
    "\n",
    "# For labels\n",
    "labels_flat = data[[0]].values.ravel()\n",
    "labels_count = np.unique(labels_flat).shape[0]\n",
    "labels = dense_to_one_hot(labels_flat, labels_count)\n",
    "labels = labels.astype(np.uint8)\n",
    "\n",
    "# Split data into training & validation\n",
    "validation_images = images[:VALIDATION_SIZE]\n",
    "validation_labels = labels[:VALIDATION_SIZE]\n",
    "\n",
    "train_images = images[VALIDATION_SIZE:]\n",
    "train_labels = labels[VALIDATION_SIZE:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create model with 2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Input and Output\n",
    "X = tf.placeholder('float', shape=[None, image_size])       # mnist data image of shape 28*28=784\n",
    "Y_gt = tf.placeholder('float', shape=[None, labels_count])    # 0-9 digits recognition => 10 classes\n",
    "drop_conv = tf.placeholder('float')\n",
    "drop_hidden = tf.placeholder('float')\n",
    "\n",
    "\n",
    "# Model Parameters\n",
    "W1 = tf.get_variable(\"W1\", shape=[5, 5, 1, 32], initializer=weight_xavier_init(5*5*1, 32))\n",
    "W2 = tf.get_variable(\"W2\", shape=[5, 5, 32, 64], initializer=weight_xavier_init(5*5*32, 64))\n",
    "W3_FC1 = tf.get_variable(\"W3_FC1\", shape=[64*7*7, 1024], initializer=weight_xavier_init(64*7*7, 1024))\n",
    "W4_FC2 = tf.get_variable(\"W4_FC2\", shape=[1024, labels_count], initializer=weight_xavier_init(1024, labels_count))\n",
    "\n",
    "#W1 = weight_variable([5, 5, 1, 32])              # 5x5x1 conv, 32 outputs\n",
    "#W2 = weight_variable([5, 5, 32, 64])             # 5x5x32 conv, 64 outputs\n",
    "#W3_FC1 = weight_variable([64 * 7 * 7, 1024])     # FC: 64x7x7 inputs, 1024 outputs\n",
    "#W4_FC2 = weight_variable([1024, labels_count])   # FC: 1024 inputs, 10 outputs (labels)\n",
    "\n",
    "B1 = bias_variable([32])\n",
    "B2 = bias_variable([64])\n",
    "B3_FC1 = bias_variable([1024])\n",
    "B4_FC2 = bias_variable([labels_count])\n",
    "\n",
    "\n",
    "# CNN model\n",
    "X1 = tf.reshape(X, [-1,image_width , image_height,1])                   # shape=(?, 28, 28, 1)\n",
    "    \n",
    "# Layer 1\n",
    "l1_conv = tf.nn.relu(conv2d(X1, W1) + B1)                               # shape=(?, 28, 28, 32)\n",
    "l1_pool = max_pool_2x2(l1_conv)                                         # shape=(?, 14, 14, 32)\n",
    "l1_drop = tf.nn.dropout(l1_pool, drop_conv)\n",
    "\n",
    "# Layer 2\n",
    "l2_conv = tf.nn.relu(conv2d(l1_drop, W2)+ B2)                           # shape=(?, 14, 14, 64)\n",
    "l2_pool = max_pool_2x2(l2_conv)                                         # shape=(?, 7, 7, 64)\n",
    "l2_drop = tf.nn.dropout(l2_pool, drop_conv) \n",
    "\n",
    "# Layer 3 - FC1\n",
    "l3_flat = tf.reshape(l2_drop, [-1, W3_FC1.get_shape().as_list()[0]])    # shape=(?, 1024)\n",
    "l3_feed = tf.nn.relu(tf.matmul(l3_flat, W3_FC1)+ B3_FC1) \n",
    "l3_drop = tf.nn.dropout(l3_feed, drop_hidden)\n",
    "\n",
    "# Layer 4 - FC2\n",
    "Y_pred = tf.nn.softmax(tf.matmul(l3_drop, W4_FC2)+ B4_FC2)              # shape=(?, 10)\n",
    "\n",
    "\n",
    "\n",
    "# Cost function and training \n",
    "cost = -tf.reduce_sum(Y_gt*tf.log(Y_pred))\n",
    "regularizer = (tf.nn.l2_loss(W3_FC1) + tf.nn.l2_loss(B3_FC1) + tf.nn.l2_loss(W4_FC2) + tf.nn.l2_loss(B4_FC2))\n",
    "cost += 5e-4 * regularizer\n",
    "\n",
    "#train_op = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cost)\n",
    "train_op = tf.train.RMSPropOptimizer(LEARNING_RATE, 0.9).minimize(cost)\n",
    "correct_predict = tf.equal(tf.argmax(Y_pred, 1), tf.argmax(Y_gt, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predict, 'float'))\n",
    "predict = tf.argmax(Y_pred, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: training / testing => 0.88 / 0.88 for step 0\n",
      "Accuracy: training / testing => 1.00 / 0.96 for step 1\n",
      "Accuracy: training / testing => 0.96 / 0.96 for step 2\n",
      "Accuracy: training / testing => 0.92 / 0.96 for step 3\n",
      "Accuracy: training / testing => 1.00 / 0.96 for step 4\n",
      "Accuracy: training / testing => 1.00 / 0.96 for step 5\n",
      "Accuracy: training / testing => 1.00 / 0.96 for step 6\n",
      "Accuracy: training / testing => 1.00 / 0.96 for step 7\n",
      "Accuracy: training / testing => 0.96 / 0.96 for step 8\n",
      "Accuracy: training / testing => 1.00 / 0.96 for step 9\n",
      "Accuracy: training / testing => 1.00 / 0.96 for step 10\n",
      "Accuracy: training / testing => 1.00 / 0.96 for step 20\n",
      "Accuracy: training / testing => 1.00 / 0.96 for step 30\n",
      "Accuracy: training / testing => 1.00 / 0.96 for step 40\n",
      "Accuracy: training / testing => 1.00 / 0.96 for step 50\n",
      "Accuracy: training / testing => 0.96 / 0.96 for step 60\n",
      "Accuracy: training / testing => 1.00 / 0.96 for step 70\n",
      "Accuracy: training / testing => 1.00 / 0.96 for step 80\n",
      "Accuracy: training / testing => 0.96 / 0.96 for step 90\n",
      "Accuracy: training / testing => 1.00 / 0.96 for step 99\n",
      "Accuracy: 99.000%\n"
     ]
    }
   ],
   "source": [
    "epochs_completed = 0\n",
    "index_in_epoch = 0\n",
    "num_examples = train_images.shape[0]\n",
    "\n",
    "# start TensorFlow session\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "# visualisation variables\n",
    "train_accuracies = []\n",
    "validation_accuracies = []\n",
    "\n",
    "DISPLAY_STEP=1\n",
    "\n",
    "for i in range(TRAINING_EPOCHS):\n",
    "\n",
    "    #get new batch\n",
    "    batch_xs, batch_ys = next_batch(BATCH_SIZE)        \n",
    "\n",
    "    # check progress on every 1st,2nd,...,10th,20th,...,100th... step\n",
    "    if i%DISPLAY_STEP == 0 or (i+1) == TRAINING_EPOCHS:\n",
    "        \n",
    "        train_accuracy = accuracy.eval(feed_dict={X:batch_xs, \n",
    "                                                  Y_gt: batch_ys,\n",
    "                                                  drop_conv: DROPOUT_CONV, \n",
    "                                                  drop_hidden: DROPOUT_HIDDEN})       \n",
    "        if(VALIDATION_SIZE):\n",
    "            validation_accuracy = accuracy.eval(feed_dict={ X: validation_images[0:BATCH_SIZE], \n",
    "                                                            Y_gt: validation_labels[0:BATCH_SIZE],\n",
    "                                                            drop_conv: DROPOUT_CONV, drop_hidden: DROPOUT_HIDDEN})                                  \n",
    "            print('Accuracy: training / testing => %.2f / %.2f for step %d'%(train_accuracy, validation_accuracy, i))\n",
    "            \n",
    "            validation_accuracies.append(validation_accuracy)\n",
    "            \n",
    "        else:\n",
    "             print('training_accuracy => %.4f for step %d'%(train_accuracy, i))\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        # increase DISPLAY_STEP\n",
    "        if i%(DISPLAY_STEP*10) == 0 and i:\n",
    "            DISPLAY_STEP *= 10\n",
    "    # train on batch\n",
    "    sess.run(train_op, feed_dict={X: batch_xs, Y_gt: batch_ys, drop_conv: DROPOUT_CONV, drop_hidden: DROPOUT_HIDDEN})\n",
    "\n",
    "\n",
    "# check final accuracy on validation set  \n",
    "if(VALIDATION_SIZE):\n",
    "    validation_accuracy = accuracy.eval(feed_dict={X: validation_images, \n",
    "                                                   Y_gt: validation_labels,\n",
    "                                                   drop_conv: DROPOUT_CONV, drop_hidden: DROPOUT_HIDDEN})\n",
    "    print('Accuracy: %.3f%%'%(validation_accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
